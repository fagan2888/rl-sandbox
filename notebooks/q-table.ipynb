{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('FrozenLake-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q = np.zeros([env.observation_space.n, env.action_space.n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.8\n",
    "y = 0.95\n",
    "num_episodes = 2000\n",
    "rewards = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_episodes):\n",
    "    s = env.reset()\n",
    "    rewards_episode = 0\n",
    "    d = False\n",
    "    j = 0\n",
    "    while j < 99:\n",
    "        j += 1\n",
    "        a = np.argmax(Q[s,:] + np.random.randn(1, env.action_space.n)*(1.0/(i+1)))\n",
    "        s1, r, d, _ = env.step(a)\n",
    "        Q[s,a] = Q[s,a] + learning_rate*(r + y*np.max(Q[s1,:]) - Q[s,a])\n",
    "        rewards_episode += r\n",
    "        s = s1\n",
    "        if d == True:\n",
    "            break\n",
    "            rewards.append(rewards_episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score over time: 0.0\nFinal Q-Table Values\n[[2.35094573e-01 3.25063310e-03 2.95145459e-03 3.76659434e-03]\n [9.88605149e-04 5.24500506e-04 1.34501105e-03 1.54043622e-01]\n [9.98723172e-04 9.83924196e-04 9.47222292e-04 1.77832093e-01]\n [3.68042327e-04 9.41285421e-06 3.97575618e-05 4.78998504e-02]\n [4.06422687e-01 7.26822992e-04 7.02780443e-04 1.33247961e-03]\n [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n [8.48139478e-04 1.82586542e-06 3.93634832e-04 3.18360124e-05]\n [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n [1.65133277e-03 7.61437610e-04 1.05756400e-03 6.36344210e-01]\n [2.37977028e-04 6.70256576e-01 5.48062870e-04 0.00000000e+00]\n [3.70148285e-04 7.78298408e-01 1.16461853e-04 1.36065173e-04]\n [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n [0.00000000e+00 0.00000000e+00 8.77682807e-01 2.40330602e-03]\n [0.00000000e+00 0.00000000e+00 0.00000000e+00 9.95605919e-01]\n [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Score over time: \" +  str(sum(rewards)/float(num_episodes)))\n",
    "print(\"Final Q-Table Values\")\n",
    "print(Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
